{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop: Building an Information Retrieval System for Podcast Episodes\n",
    "\n",
    "## Objective:\n",
    "Create an Information Retrieval (IR) system that processes a dataset of podcast transcripts and, given a query, returns the episodes where the host and guest discuss the query topic. Use TF-IDF and BERT for vector space representation and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "### Step 1: Import Libraries\n",
    "Import necessary libraries for data handling, text processing, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import snowballstemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset\n",
    "\n",
    "Load the dataset of podcast transcripts.\n",
    "\n",
    "Find the dataset in: https://www.kaggle.com/datasets/rajneesh231/lex-fridman-podcast-transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('data/podcastdata_dataset.csv')#, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>guest</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Max Tegmark</td>\n",
       "      <td>Life 3.0</td>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Christof Koch</td>\n",
       "      <td>Consciousness</td>\n",
       "      <td>As part of MIT course 6S099 on artificial gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Steven Pinker</td>\n",
       "      <td>AI in the Age of Reason</td>\n",
       "      <td>You've studied the human mind, cognition, lang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>What difference between biological neural netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vladimir Vapnik</td>\n",
       "      <td>Statistical Learning</td>\n",
       "      <td>The following is a conversation with Vladimir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>321</td>\n",
       "      <td>Ray Kurzweil</td>\n",
       "      <td>Singularity, Superintelligence, and Immortality</td>\n",
       "      <td>By the time he gets to 2045, we'll be able to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>322</td>\n",
       "      <td>Rana el Kaliouby</td>\n",
       "      <td>Emotion AI, Social Robots, and Self-Driving Cars</td>\n",
       "      <td>there's a broader question here, right? As we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>323</td>\n",
       "      <td>Will Sasso</td>\n",
       "      <td>Comedy, MADtv, AI, Friendship, Madness, and Pr...</td>\n",
       "      <td>Once this whole thing falls apart and we are c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>324</td>\n",
       "      <td>Daniel Negreanu</td>\n",
       "      <td>Poker</td>\n",
       "      <td>you could be the seventh best player in the wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>325</td>\n",
       "      <td>Michael Levin</td>\n",
       "      <td>Biology, Life, Aliens, Evolution, Embryogenesi...</td>\n",
       "      <td>turns out that if you train a planarian and th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             guest                                              title  \\\n",
       "0      1       Max Tegmark                                           Life 3.0   \n",
       "1      2     Christof Koch                                      Consciousness   \n",
       "2      3     Steven Pinker                            AI in the Age of Reason   \n",
       "3      4     Yoshua Bengio                                      Deep Learning   \n",
       "4      5   Vladimir Vapnik                               Statistical Learning   \n",
       "..   ...               ...                                                ...   \n",
       "314  321      Ray Kurzweil    Singularity, Superintelligence, and Immortality   \n",
       "315  322  Rana el Kaliouby   Emotion AI, Social Robots, and Self-Driving Cars   \n",
       "316  323        Will Sasso  Comedy, MADtv, AI, Friendship, Madness, and Pr...   \n",
       "317  324   Daniel Negreanu                                              Poker   \n",
       "318  325     Michael Levin  Biology, Life, Aliens, Evolution, Embryogenesi...   \n",
       "\n",
       "                                                  text  \n",
       "0    As part of MIT course 6S099, Artificial Genera...  \n",
       "1    As part of MIT course 6S099 on artificial gene...  \n",
       "2    You've studied the human mind, cognition, lang...  \n",
       "3    What difference between biological neural netw...  \n",
       "4    The following is a conversation with Vladimir ...  \n",
       "..                                                 ...  \n",
       "314  By the time he gets to 2045, we'll be able to ...  \n",
       "315  there's a broader question here, right? As we ...  \n",
       "316  Once this whole thing falls apart and we are c...  \n",
       "317  you could be the seventh best player in the wh...  \n",
       "318  turns out that if you train a planarian and th...  \n",
       "\n",
       "[319 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Text Preprocessing\n",
    "\n",
    "You know what to do ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Delete punctuation\n",
    "* Delete stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    As part of MIT course 6S099, Artificial Genera...\n",
      "1    As part of MIT course 6S099 on artificial gene...\n",
      "2    You've studied the human mind, cognition, lang...\n",
      "3    What difference between biological neural netw...\n",
      "4    The following is a conversation with Vladimir ...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "corpus = df['text']\n",
    "print(corpus.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we delete punctuation\n",
    "corpus_nopunct = []\n",
    "\n",
    "for doc in corpus:\n",
    "    corpus_nopunct.append(doc.lower().translate(str.maketrans('', '', string.punctuation)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_nopunct'] = corpus_nopunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>guest</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>text_nopunct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Max Tegmark</td>\n",
       "      <td>Life 3.0</td>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>as part of mit course 6s099 artificial general...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Christof Koch</td>\n",
       "      <td>Consciousness</td>\n",
       "      <td>As part of MIT course 6S099 on artificial gene...</td>\n",
       "      <td>as part of mit course 6s099 on artificial gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Steven Pinker</td>\n",
       "      <td>AI in the Age of Reason</td>\n",
       "      <td>You've studied the human mind, cognition, lang...</td>\n",
       "      <td>youve studied the human mind cognition languag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>What difference between biological neural netw...</td>\n",
       "      <td>what difference between biological neural netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vladimir Vapnik</td>\n",
       "      <td>Statistical Learning</td>\n",
       "      <td>The following is a conversation with Vladimir ...</td>\n",
       "      <td>the following is a conversation with vladimir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>321</td>\n",
       "      <td>Ray Kurzweil</td>\n",
       "      <td>Singularity, Superintelligence, and Immortality</td>\n",
       "      <td>By the time he gets to 2045, we'll be able to ...</td>\n",
       "      <td>by the time he gets to 2045 well be able to mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>322</td>\n",
       "      <td>Rana el Kaliouby</td>\n",
       "      <td>Emotion AI, Social Robots, and Self-Driving Cars</td>\n",
       "      <td>there's a broader question here, right? As we ...</td>\n",
       "      <td>theres a broader question here right as we bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>323</td>\n",
       "      <td>Will Sasso</td>\n",
       "      <td>Comedy, MADtv, AI, Friendship, Madness, and Pr...</td>\n",
       "      <td>Once this whole thing falls apart and we are c...</td>\n",
       "      <td>once this whole thing falls apart and we are c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>324</td>\n",
       "      <td>Daniel Negreanu</td>\n",
       "      <td>Poker</td>\n",
       "      <td>you could be the seventh best player in the wh...</td>\n",
       "      <td>you could be the seventh best player in the wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>325</td>\n",
       "      <td>Michael Levin</td>\n",
       "      <td>Biology, Life, Aliens, Evolution, Embryogenesi...</td>\n",
       "      <td>turns out that if you train a planarian and th...</td>\n",
       "      <td>turns out that if you train a planarian and th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             guest                                              title  \\\n",
       "0      1       Max Tegmark                                           Life 3.0   \n",
       "1      2     Christof Koch                                      Consciousness   \n",
       "2      3     Steven Pinker                            AI in the Age of Reason   \n",
       "3      4     Yoshua Bengio                                      Deep Learning   \n",
       "4      5   Vladimir Vapnik                               Statistical Learning   \n",
       "..   ...               ...                                                ...   \n",
       "314  321      Ray Kurzweil    Singularity, Superintelligence, and Immortality   \n",
       "315  322  Rana el Kaliouby   Emotion AI, Social Robots, and Self-Driving Cars   \n",
       "316  323        Will Sasso  Comedy, MADtv, AI, Friendship, Madness, and Pr...   \n",
       "317  324   Daniel Negreanu                                              Poker   \n",
       "318  325     Michael Levin  Biology, Life, Aliens, Evolution, Embryogenesi...   \n",
       "\n",
       "                                                  text  \\\n",
       "0    As part of MIT course 6S099, Artificial Genera...   \n",
       "1    As part of MIT course 6S099 on artificial gene...   \n",
       "2    You've studied the human mind, cognition, lang...   \n",
       "3    What difference between biological neural netw...   \n",
       "4    The following is a conversation with Vladimir ...   \n",
       "..                                                 ...   \n",
       "314  By the time he gets to 2045, we'll be able to ...   \n",
       "315  there's a broader question here, right? As we ...   \n",
       "316  Once this whole thing falls apart and we are c...   \n",
       "317  you could be the seventh best player in the wh...   \n",
       "318  turns out that if you train a planarian and th...   \n",
       "\n",
       "                                          text_nopunct  \n",
       "0    as part of mit course 6s099 artificial general...  \n",
       "1    as part of mit course 6s099 on artificial gene...  \n",
       "2    youve studied the human mind cognition languag...  \n",
       "3    what difference between biological neural netw...  \n",
       "4    the following is a conversation with vladimir ...  \n",
       "..                                                 ...  \n",
       "314  by the time he gets to 2045 well be able to mu...  \n",
       "315  theres a broader question here right as we bui...  \n",
       "316  once this whole thing falls apart and we are c...  \n",
       "317  you could be the seventh best player in the wh...  \n",
       "318  turns out that if you train a planarian and th...  \n",
       "\n",
       "[319 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sebitas/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_norep = []\n",
    "\n",
    "for doc in corpus_nopunct:\n",
    "    clean_doc = []\n",
    "    doc_array = doc.split(' ')\n",
    "    for word in doc_array:\n",
    "        if word not in stopw:\n",
    "            clean_doc.append(word)\n",
    "    corpus_norep.append(' '.join(clean_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_nostopw'] = corpus_norep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>guest</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>text_nopunct</th>\n",
       "      <th>text_nostopw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Max Tegmark</td>\n",
       "      <td>Life 3.0</td>\n",
       "      <td>As part of MIT course 6S099, Artificial Genera...</td>\n",
       "      <td>as part of mit course 6s099 artificial general...</td>\n",
       "      <td>part mit course 6s099 artificial general intel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Christof Koch</td>\n",
       "      <td>Consciousness</td>\n",
       "      <td>As part of MIT course 6S099 on artificial gene...</td>\n",
       "      <td>as part of mit course 6s099 on artificial gene...</td>\n",
       "      <td>part mit course 6s099 artificial general intel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Steven Pinker</td>\n",
       "      <td>AI in the Age of Reason</td>\n",
       "      <td>You've studied the human mind, cognition, lang...</td>\n",
       "      <td>youve studied the human mind cognition languag...</td>\n",
       "      <td>youve studied human mind cognition language vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Yoshua Bengio</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>What difference between biological neural netw...</td>\n",
       "      <td>what difference between biological neural netw...</td>\n",
       "      <td>difference biological neural networks artifici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vladimir Vapnik</td>\n",
       "      <td>Statistical Learning</td>\n",
       "      <td>The following is a conversation with Vladimir ...</td>\n",
       "      <td>the following is a conversation with vladimir ...</td>\n",
       "      <td>following conversation vladimir vapnik hes co ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>321</td>\n",
       "      <td>Ray Kurzweil</td>\n",
       "      <td>Singularity, Superintelligence, and Immortality</td>\n",
       "      <td>By the time he gets to 2045, we'll be able to ...</td>\n",
       "      <td>by the time he gets to 2045 well be able to mu...</td>\n",
       "      <td>time gets 2045 well able multiply intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>322</td>\n",
       "      <td>Rana el Kaliouby</td>\n",
       "      <td>Emotion AI, Social Robots, and Self-Driving Cars</td>\n",
       "      <td>there's a broader question here, right? As we ...</td>\n",
       "      <td>theres a broader question here right as we bui...</td>\n",
       "      <td>theres broader question right build socially e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>323</td>\n",
       "      <td>Will Sasso</td>\n",
       "      <td>Comedy, MADtv, AI, Friendship, Madness, and Pr...</td>\n",
       "      <td>Once this whole thing falls apart and we are c...</td>\n",
       "      <td>once this whole thing falls apart and we are c...</td>\n",
       "      <td>whole thing falls apart climbing kudzu vines s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>324</td>\n",
       "      <td>Daniel Negreanu</td>\n",
       "      <td>Poker</td>\n",
       "      <td>you could be the seventh best player in the wh...</td>\n",
       "      <td>you could be the seventh best player in the wh...</td>\n",
       "      <td>could seventh best player whole world like lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>325</td>\n",
       "      <td>Michael Levin</td>\n",
       "      <td>Biology, Life, Aliens, Evolution, Embryogenesi...</td>\n",
       "      <td>turns out that if you train a planarian and th...</td>\n",
       "      <td>turns out that if you train a planarian and th...</td>\n",
       "      <td>turns train planarian cut heads tail regenerat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             guest                                              title  \\\n",
       "0      1       Max Tegmark                                           Life 3.0   \n",
       "1      2     Christof Koch                                      Consciousness   \n",
       "2      3     Steven Pinker                            AI in the Age of Reason   \n",
       "3      4     Yoshua Bengio                                      Deep Learning   \n",
       "4      5   Vladimir Vapnik                               Statistical Learning   \n",
       "..   ...               ...                                                ...   \n",
       "314  321      Ray Kurzweil    Singularity, Superintelligence, and Immortality   \n",
       "315  322  Rana el Kaliouby   Emotion AI, Social Robots, and Self-Driving Cars   \n",
       "316  323        Will Sasso  Comedy, MADtv, AI, Friendship, Madness, and Pr...   \n",
       "317  324   Daniel Negreanu                                              Poker   \n",
       "318  325     Michael Levin  Biology, Life, Aliens, Evolution, Embryogenesi...   \n",
       "\n",
       "                                                  text  \\\n",
       "0    As part of MIT course 6S099, Artificial Genera...   \n",
       "1    As part of MIT course 6S099 on artificial gene...   \n",
       "2    You've studied the human mind, cognition, lang...   \n",
       "3    What difference between biological neural netw...   \n",
       "4    The following is a conversation with Vladimir ...   \n",
       "..                                                 ...   \n",
       "314  By the time he gets to 2045, we'll be able to ...   \n",
       "315  there's a broader question here, right? As we ...   \n",
       "316  Once this whole thing falls apart and we are c...   \n",
       "317  you could be the seventh best player in the wh...   \n",
       "318  turns out that if you train a planarian and th...   \n",
       "\n",
       "                                          text_nopunct  \\\n",
       "0    as part of mit course 6s099 artificial general...   \n",
       "1    as part of mit course 6s099 on artificial gene...   \n",
       "2    youve studied the human mind cognition languag...   \n",
       "3    what difference between biological neural netw...   \n",
       "4    the following is a conversation with vladimir ...   \n",
       "..                                                 ...   \n",
       "314  by the time he gets to 2045 well be able to mu...   \n",
       "315  theres a broader question here right as we bui...   \n",
       "316  once this whole thing falls apart and we are c...   \n",
       "317  you could be the seventh best player in the wh...   \n",
       "318  turns out that if you train a planarian and th...   \n",
       "\n",
       "                                          text_nostopw  \n",
       "0    part mit course 6s099 artificial general intel...  \n",
       "1    part mit course 6s099 artificial general intel...  \n",
       "2    youve studied human mind cognition language vi...  \n",
       "3    difference biological neural networks artifici...  \n",
       "4    following conversation vladimir vapnik hes co ...  \n",
       "..                                                 ...  \n",
       "314  time gets 2045 well able multiply intelligence...  \n",
       "315  theres broader question right build socially e...  \n",
       "316  whole thing falls apart climbing kudzu vines s...  \n",
       "317  could seventh best player whole world like lit...  \n",
       "318  turns train planarian cut heads tail regenerat...  \n",
       "\n",
       "[319 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo de lenguaje de spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Inicializar el stemmer\n",
    "stemmer = snowballstemmer.stemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunciÃ³n para lematizar y stematizar texto\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    stemmed_tokens = [stemmer.stemWord(token.text) for token in doc]\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc]\n",
    "    return ' '.join(stemmed_tokens), ' '.join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_corpus, lemmatised_corpus = preprocess_text(corpus_norep[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 4: Vector Space Representation - TF-IDF\n",
    "\n",
    "Create TF-IDF vector representations of the transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_mtx = vectorizer.fit_transform(df['text_nostopw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Vector Space Representation - BERT\n",
    "\n",
    "Create BERT vector representations of the transcripts using a pre-trained BERT model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Query Processing\n",
    "\n",
    "Define a function to process the query and compute similarity scores using both TF-IDF and BERT embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Computer Science'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = vectorizer.transform([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(tfidf_mtx, query_vector )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Retrieve and Compare Results\n",
    "\n",
    "Define a function to retrieve the top results based on similarity scores for both TF-IDF and BERT representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Test the IR System\n",
    "\n",
    "Test the system with a sample query.\n",
    "\n",
    "Retrieve and display the top results using both TF-IDF and BERT representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_tfidf(query):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(tfidf_mtx, query_vector)\n",
    "    similarities_df = pd.DataFrame(similarities, columns=['sim'])\n",
    "    similarities_df['ep'] = df['title']\n",
    "    return similarities_df.sort_values(by='sim', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim</th>\n",
       "      <th>ep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.383218</td>\n",
       "      <td>Spotify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.100674</td>\n",
       "      <td>Legendary Music Producer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.091897</td>\n",
       "      <td>The Existential Threat of Engineered Viruses a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.086500</td>\n",
       "      <td>The Next Generation of Big Ideas and Brave Minds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.068726</td>\n",
       "      <td>Virtual Reality, Social Media &amp; the Future of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.067685</td>\n",
       "      <td>Music, AI, and the Future of Humanity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.065007</td>\n",
       "      <td>iPhone, iPod, and Nest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.061245</td>\n",
       "      <td>Predicates, Invariants, and the Essence of Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.052573</td>\n",
       "      <td>The Power of Introverts and Loneliness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.050466</td>\n",
       "      <td>Machine Learning, Recommender Systems, and the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sim                                                 ep\n",
       "29   0.383218                                            Spotify\n",
       "272  0.100674                           Legendary Music Producer\n",
       "192  0.091897  The Existential Threat of Engineered Viruses a...\n",
       "157  0.086500   The Next Generation of Big Ideas and Brave Minds\n",
       "216  0.068726  Virtual Reality, Social Media & the Future of ...\n",
       "278  0.067685              Music, AI, and the Future of Humanity\n",
       "287  0.065007                             iPhone, iPod, and Nest\n",
       "71   0.061245  Predicates, Invariants, and the Essence of Int...\n",
       "291  0.052573             The Power of Introverts and Loneliness\n",
       "74   0.050466  Machine Learning, Recommender Systems, and the..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_tfidf('music')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Compare Results\n",
    "\n",
    "Analyze and compare the results obtained from TF-IDF and BERT representations.\n",
    "\n",
    "Discuss the differences, strengths, and weaknesses of each method based on the retrieval results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "\n",
    "* Follow the steps outlined above to implement the IR system.\n",
    "* Run the provided code snippets to understand how each part of the system works.\n",
    "* Test the system with various queries to observe the results from both TF-IDF and BERT representations.\n",
    "* Compare and analyze the results. Discuss the pros and cons of each method.\n",
    "* Document your findings and any improvements you make to the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
